<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252" charset="utf-8">
        <title>Yibo Liu - Ph.D. </title>
<style type="text/css"></style></head>
    <body><table border="0" width="980px" align="center"><tbody><tr><td>
    
        </td><td valign="top">
<!--            <img src="images/cmuscslogo.gif">
                <img src="images/rilogo.png"> -->
        <br>
        <table style="font-size: 11pt;" border="0" width="100%">
            <tbody><tr>
                <td width="50%">
                    <!-- <img width="300" src="./index_files/mypic.jpeg" border="0"> -->
                    <!-- <img width="300" src="./index_files/mypic2.jpg" border="0"> -->
                    <!-- <img width="250" src="./index_files/mypic3.jpg" border="0"> -->
                    <img width="300" src="./index_files/yibo.JPG" border="0">
                </td>
                <td>
                    <font face="helvetica , ariel, &#39;sans serif&#39;" size="6"> 
                        <b>Yibo Liu</b><br><br>
                    </font>
                    <font face="helvetica , ariel, &#39;sans serif&#39;" size="4"> 
                        Ph.D.<br>
                        York University, Toronto<br><br>
			IEEE Member<br><br>
                        buaayorklau at gmail.com<br><br>
                        [<a href="https://github.com/yorklyb" border="0">GitHub</a>]
                        [<a href="https://scholar.google.ca/citations?user=zqDgDQ4AAAAJ&hl=en&oi=ao" border="0">Google Scholar</a>]
                        [<a href="index_files/yibo_liu_cv_2025_02_24.pdf" border="0">Resume</a>]
                        [<a href="https://www.linkedin.com/in/yibo-liu/" border="0">Linkedin</a>]
                    </font>
                </td>
            </tr>
        </tbody></table> 
        <p>
        </p><hr size="2" align="left" noshade="">
        <p>
        
        <font face="helvetica, ariel, &#39;sans serif&#39;">
        <!--</font></p><h2><font face="helvetica, ariel, &#39;sans serif&#39;">About Me</font></h2><font face="helvetica, ariel, &#39;sans serif&#39;">-->
	I obtained my Ph.D. degree from York University in Jan 2025, supervised by Professor <a href="https://lassonde.yorku.ca/users/jjshan">Jinjun Shan</a>. I obtained my bachelor's degree in 2017 and my master's degree in 2020, both at <a href="https://en.wikipedia.org/wiki/Beihang_University"> Beihang University (BUAA).</a>. <br><br>
	My Ph.D. study began with research in robotic vision. From Jun. 2022 to Feb. 2025, I have been working as an associate researcher (part-time internship) at Huawei Noah Ark's Lab in Markham, where I conduct product-oriented academic research. My research interests lie in the domains of 3D Computer Vision, AIGC, Vision Language, and Embodied AI. 
		<br><br>
		<a href="https://eccv.ecva.net/virtual/2024/poster/1732">VQA-Diff (ECCV2024)</a>, <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Liu_MV-DeepSDF_Implicit_Modeling_with_Multi-Sweep_Point_Clouds_for_3D_Vehicle_ICCV_2023_paper.html">MV-DeepSDF (ICCV2023)</a>, <a href="https://neurips.cc/virtual/2024/101470">NeurIPS 2024 Workshop Paper</a>  (Top-3 winner of <a href="https://omniobject3d.github.io/challenge.html">OmniObject3D challenge</a> at ICCV2023),
		and <a href="https://hippope.github.io/">HIPPo</a> summarize my work. 
        <br>
        
        <!-- <br><br> -->
        </p><hr size="2" align="left" noshade="">

        <h3>News </h3>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <span style="font-size: 10pt;">
<!--             <b>[Sept 2023]</b> I was included on a list of <a href="https://www.technologyreview.com/innovator/richard-zhang/">35 Innovators Under 35</a> by MIT Technology Review! Please see <a href="https://blog.adobe.com/en/publish/2023/09/12/adobe-research-scientist-named-top-innovator-under-35-mit-technology-review">this article</a> by Adobe and <a href="https://www.youtube.com/watch?v=YQW32sf9noE">this 5 min overview video</a> for more information.<br> -->
            <!-- <b>[Nov 2023]</b> I appeared on the <a href="https://twimlai.com/podcast/twimlai/visual-generative-ai-ecosystem-challenges/">TWiML podcast</a>, discussing building a healthy GenAI ecosystem for creators, consumers, and contributors. Links: <a href="https://open.spotify.com/episode/6V8zgyf9f6Q6p7rdRhrbpU?si=6670478bdffd46b5">Spotify</a>, <a href="https://podcasts.apple.com/us/podcast/visual-generative-ai-ecosystem-challenges-with-richard/id1116303051?i=1000635452895">Apple</a>, <a href="https://dcs.megaphone.fm/MLN6292733087.mp3">File</a> (40 min); <a href="https://www.youtube.com/watch?v=PdHmoqS70r0">YouTube</a> (51 min).<br> -->
        <b>[Jan 2025]</b> L-PR was accepted to IEEE Transactions on Instrumentation & Measurement. </a><br>
	<b>[Jan 2025]</b> Defended my Ph.D. thesis & became Dr. Liu. </a><br> 
	<b>[Sep 2024]</b> I gave a <a href="https://www.youtube.com/watch?v=Q9PpQylYpEw">talk</a> at the University of Toronto (Toronto Computational Imaging Group). </a><br>
            <b>[Sep 2024]</b> I'm invited to give a talk at <a href="https://www.bilibili.com/video/BV1eKtoeVEJA/?spm_id_from=333.999.0.0">3D Vision Workshop (3D 视觉工坊)</a>.<br>
		<b>[Aug 2024]</b> VQA-Diff was accepted to ECCV 2024.<br>
            <b>[Jun 2024]</b> Got an internship offer from Amazon based in Sunnyvale (virtual try-on group).<br>
                <b>[Oct 2023]</b>  Got 3rd place in the OmniObject Challenge (AIGC) at ICCV 2023.<br>
            <b>[Sep 2023]</b> MV-DeepSDF was accepted to ICCV 2023.<br>
            
            <!-- <b>[May 2019]</b> Our work on anti-aliasing convolutional networks has been accepted to ICML 2019. Try anti-aliasing your convnet <a href="https://github.com/adobe/antialiased-cnns">here</a>!<br> -->
            <!-- <b>[Aug 2018]</b> I will be presenting at the Thesis Fast Forward session at SIGGRAPH on Tuesday 8/14, 2:00pm.<br> -->
            <!-- <b>[Jun 2018]</b> We will be presenting our <a href="https://richzhang.github.io/PerceptualSimilarity/">project</a> on perceptual metrics at CVPR, Tuesday 6/19, 10:10am. Try our metric <a href="https://github.com/richzhang/PerceptualSimilarity">here</a>!<br> -->
            <!-- <b>[May 2018]</b> I have <a href="./index_files/graduation.jpg">graduated</a> from UC Berkeley and have joined Adobe Research as a Research Scientist in San Francisco! -->
            </span>

<!--         </p><hr size="2" align="left" noshade="">

        <h3>Internship </h3>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <span style="font-size: 10pt;">
            If you have similar interests and are interested in collaborating during a Summer 2023 internship, I'd be happy to hear from you! <b>Please apply <a href="https://research.adobe.com/careers/internships/">here</a> first</b>. Tell me about your past research experience and what you would potentially like to do. The goal of an internship is a publication, usually CVPR or SIGGRAPH. Interns are typically PhD students; the number of slots is limited, so we unfortunately cannot accept everyone.
            </span>
        </font>
 -->
        </p><hr size="2" align="left" noshade="">

        <h2>Selected Publications </h2>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
	<h3>Conferences</h3>
            <table cellspacing="15">
				<tbody>
                <tr>
                    <td width="30%" align=center>
                        <img width="250" align="center" src="./index_files/vqadiff.png" border="0"> &nbsp;

			    
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>VQA-Diff: Exploiting VQA and Diffusion for Zero-Shot Image-to-3D Vehicle Asset Generation in Autonomous Driving</b> <br> <br> 
                        <span style="font-size: 10pt;">
			<b>Yibo Liu *</b>,
                        Zheyuan Yang *, 
                        Guile Wu, 
			Yuan Ren, Kejian Lin, Bingbing Liu, Yang Liu, Jinjun Shan.
                        <br> <br> 
                        ECCV, 2024. <br> <br> 
                        [<a href="https://eccv.ecva.net/virtual/2024/poster/1732">Paper</a>]
			[<a href="https://www.youtube.com/watch?v=eCZl5tG6pLU&t=108s">Video (YouTube)</a>]
			[<a href="https://www.bilibili.com/video/BV1KVnXeqE25/?spm_id_from=333.999.0.0">Video (Bilibili)</a>]
			[<a href="index_files/eccv_graph.png">Poster</a>]
                        <br>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=center>
                        <img width="250" align="center" src="./index_files/mvdeepsdf.png" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>MV-DeepSDF: Implicit Modeling with Multi-Sweep Point Clouds for 3D Vehicle Reconstruction in Autonomous Driving</b> <br> <br>
                        <span style="font-size: 10pt;">
                        <b>Yibo Liu</b>,
                        Kelly Zhu, 
                        Guile Wu, 
			Yuan Ren, Bingbing Liu, Yang Liu, Jinjun Shan.
                        <br> <br>
                        ICCV, 2023. <br><br>
                        [<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Liu_MV-DeepSDF_Implicit_Modeling_with_Multi-Sweep_Point_Clouds_for_3D_Vehicle_ICCV_2023_paper.html">Paper</a>]
                        [<a href="https://www.youtube.com/watch?v=HONluMoFkeI">Video (YouTube)</a>]
			[<a href="https://www.bilibili.com/video/BV1zK4y1w7mQ/">Video (Bilibili)</a>]
			[<a href="index_files/iccv_poster.png">Poster</a>]
                        <br>
                    </td>
                </tr>
                <tr>

			 <td width="30%" align=center>
                        <img width="250" align="center" src="./index_files/omni.png" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">

                        <b>Learning Effective NeRFs and SDFs Representations with 3D Generative Adversarial Networks for 3D Object Generation</b> <br> <br>
                        <span style="font-size: 10pt;">
			Zheyuan Yang*,
                        <b>Yibo Liu*</b>,
                        Guile Wu, Tongtong Cao,
			Yuan Ren, Bingbing Liu, Yang Liu.
                        <br>
			NeurIPS 2024 Workshop: Symmetry and Geometry in Neural Representations <br>
                        OmniObject3D Challenge at ICCV 2023 (AI for 3D Content Creation Workshop). <br>
			[<a href="https://neurips.cc/virtual/2024/101470">NeurIPS Workshop Poster Page</a>]
			[<a href="https://arxiv.org/abs/2309.16110v2">ArXiv</a>]
			[<a href="index_files/cert.png">Certificate</a>]
			[<a href="https://omniobject3d.github.io/challenge.html">Challenge Introduction</a>]
                        
			
                        <br>
                    </td>
								</tr>

</tr> <!-- 结束上一行 -->
<td width="30%" align=center>
                        <img width="250" align="center" src="./index_files/ghost.gif" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">

                        <b>Application of Ghost-DeblurGAN to Fiducial Marker Detection</b> <br> <br>
                        <span style="font-size: 10pt;">
                        <b>Yibo Liu</b>,
				Amaldev Haridevan,
                       Hunter Schofield,
			Jinjun Shan.
                        <br> <br>
                        IROS, 2022. <br><br>
			[<a href="https://ieeexplore.ieee.org/document/9981701">Paper</a>]
                        [<a href="https://github.com/York-SDCNLab/Ghost-DeblurGAN">GitHub</a>]
			[<a href="https://www.bilibili.com/video/BV1r14y1Y7M3/?spm_id_from=333.999.0.0">Video</a>]
			[<a href="./index_files/ghost.jpg">Poster</a>]
                        <br>
                    </td>
</tr>
                <tr>

				<td width="30%" align=center>
                        <img width="250" align="center" src="./index_files/mfi.png" border="0"> &nbsp;
                    </td>

				
                    <td>
                        <span style="font-size: 12pt;">

                        <b>Navigation of a Self-Driving Vehicle Using One Fiducial Marker</b> <br> 
                        <span style="font-size: 10pt;">
                        <b>Yibo Liu</b>,
                       Hunter Schofield,
			Jinjun Shan.
                        <br> 
                        International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI), 2021. <br>
			[<a href="https://ieeexplore.ieee.org/document/9591194">Paper</a>]
			[<a href="https://www.youtube.com/watch?v=lrHy3oRdQj4">Video</a>]
			[<a href="./index_files/mfiposter.png">Poster</a>]
                        <br>
                    </td>
				</tr>
                <tr>


				
</table> <!-- 关闭当前表格 -->

<h3>Journals</h3> <!-- 这里放 Journals 小标题 -->

<table cellspacing="15"> <!-- 重新开启一个新表格 -->
    <tbody>
        <tr>
				<td width="30%" align=center>
                        <img width="250" align="center" src="./index_files/tim.png" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">

                        <b>L-PR: Exploiting LiDAR Fiducial Marker for Unordered Low Overlap Multiview Point Cloud Registration</b> <br> <br>
                        <span style="font-size: 10pt;">
                        <b>Yibo Liu</b>,
				Jinjun Shan,
				Amaldev Haridevan,
                       Shuo Zhang.
                        <br> <br>
                        IEEE Transactions on Instrumentation and Measurement (TIM), 2025. <br><br>
			[<a href="https://ieeexplore.ieee.org/document/10900543">Paper</a>]
                        [<a href="https://github.com/yorklyb/L-PR">GitHub</a>]
                        <br>
                    </td>
</tr>
                <tr>

			<td width="30%" align=center>
                        <img width="250" align="center" src="./index_files/iilfm.gif" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">

                        <b>Intensity Image-based LiDAR Fiducial Marker System</b> <br> <br>
                        <span style="font-size: 10pt;">
                        <b>Yibo Liu</b>,
                       Hunter Schofield,
			Jinjun Shan.
                        <br> <br>
                        RA-L 2022. Presented at IROS 2022. <br><br>
			[<a href="https://ieeexplore.ieee.org/document/9774900">Paper</a>]
                        [<a href="https://github.com/York-SDCNLab/IILFM">Github</a>]
			[<a href="https://www.bilibili.com/video/BV1BP411H7eF/?spm_id_from=333.999.0.0">Video</a>]
			[<a href="./index_files/iilfm.jpg">Poster</a>]
                        <br>
                    </td>

				</tr>
                <tr>

			<td width="30%" align=center>
                        <img width="250" align="center" src="./index_files/tase.png" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">

                        <b>Approximate Inference Particle Filtering for Mobile Robot SLAM</b> <br> <br>
                        <span style="font-size: 10pt;">
				Shuo Zhang,
			Jinjun Shan, <b>Yibo Liu</b>.
                        <br> <br>
                        IEEE Transactions on Automation Science and Engineering (T-ASE), 2024. <br>
			[<a href="https://ieeexplore.ieee.org/document/10720199">Paper</a>]
                        <br>
                    </td>

						</tr>
                <tr>


			

			<td width="30%" align=center>
                        <img width="250" align="center" src="./index_files/tmech.png" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">

                        <b>Variational Bayesian Estimator for Mobile Robot Localization With Unknown Noise Covariance</b> <br> <br>
                        <span style="font-size: 10pt;">
				Shuo Zhang,
			Jinjun Shan, <b>Yibo Liu</b>.
                        <br> <br>
                        IEEE/ASME Transactions on Mechatronics (T-MECH), 2022. <br>
			[<a href="https://ieeexplore.ieee.org/abstract/document/9753664?casa_token=S_KEQiB8yy4AAAAA:fysuh8EM5VEbf4ccniqCYNuxnKrgKiPxO04zmcHrPEozdcekAraHZdn1Ay1ReR9P-5CETAkl">Paper</a>]
                        <br>
                    </td>
</tr>
                <tr>

			<td width="30%" align=center>
                        <img width="250" align="center" src="./index_files/csl.png" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">

                        <b>Particle Filtering on Lie Group for Mobile Robot Localization With Range-Bearing Measurements</b> <br> <br>
                        <span style="font-size: 10pt;">
			Shuo Zhang,
			Jinjun Shan, <b>Yibo Liu</b>.
                        <br>
                        IEEE Control Systems Letters, 2024. Presented at ACC 2024. <br>
			[<a href="https://ieeexplore.ieee.org/abstract/document/10347485?casa_token=uWvlVjNvki4AAAAA:nNRtU_fOeE7J8IbW8CSqUT2tUmsM-aAwAyfC5LIKcOQqNCNtr1FH9qGoZ1tV1kiX6JGd8jd-">Paper</a>]
                        <br>
                    </td>
                   
            </tbody></table>

        <h2>Reviewer Service</h2>
        <span style="font-size: 10pt;">
        <b>Conferences:</b> ICLR, NeurIPS, ICRA, IROS, ATSTATS, AIM, ICPR <br>
	<b>Journals:</b>IEEE Robotics and Automation Letters (RA-L), IEEE Robotics and Automation Magazine (RA-M), 
	IEEE Transactions on Instrumentation and Measurement (TIM), IEEE Transactions on Industrial Electronics (TIE), Robotics and Autonomous Systems (RAS). <br>
        
        <h2>Misc</h2>
	I love fishing, basketball, airsoft guns, and swimming. <br>
	The template is borrowed from [<a href="https://richzhang.github.io/">here</a>].
		
       

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75897335-1', 'auto');
  ga('send', 'pageview');
</script>
            
</font></td></tr></tbody></table><iframe frameborder="0" scrolling="no" style="border: 0px; display: none; background-color: transparent;"></iframe><div id="GOOGLE_INPUT_CHEXT_FLAG" input="null" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:false,&quot;ss&quot;:true}" style="display: none;"></div></body></html>
<br>
<div style="display: flex; justify-content: center; align-items: center;">
    <a href="https://info.flagcounter.com/f6ov">
        <img src="https://s05.flagcounter.com/map/f6ov/size_s/txt_000000/border_CCCCCC/pageviews_1/viewers_0/flags_0/" alt="Flag Counter" border="0">
    </a>
</div>
<br>
<br>
